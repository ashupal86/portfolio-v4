# Robots.txt for ashu.devinit.in
# Allow legitimate search engines, block bad bots and AI scrapers

# Good Search Engines - ALLOW
User-agent: Googlebot
User-agent: Googlebot-Image
User-agent: Googlebot-News
User-agent: Bingbot
User-agent: Slurp
User-agent: DuckDuckBot
User-agent: Baiduspider
User-agent: YandexBot
User-agent: Applebot
Allow: /

# Block AI Training Bots & Scrapers
User-agent: GPTBot
User-agent: ChatGPT-User
User-agent: CCBot
User-agent: anthropic-ai
User-agent: Claude-Web
User-agent: cohere-ai
User-agent: Omgilibot
User-agent: FacebookBot
User-agent: Diffbot
User-agent: PerplexityBot
User-agent: YouBot
Disallow: /

# Block Common Bad Bots
User-agent: AhrefsBot
User-agent: SemrushBot
User-agent: MJ12bot
User-agent: DotBot
User-agent: BLEXBot
User-agent: DataForSeoBot
User-agent: PetalBot
User-agent: MegaIndex
User-agent: Seekport
User-agent: ZoominfoBot
Disallow: /

# Block Scrapers
User-agent: SiteSnagger
User-agent: WebCopier
User-agent: WebZIP
User-agent: HTTrack
User-agent: Teleport
User-agent: WebReaper
User-agent: WebStripper
User-agent: WebSauger
User-agent: WebWhacker
Disallow: /

# Default - Allow with restrictions
User-agent: *
Allow: /
Disallow: /api/
Disallow: /*.json$
Disallow: /private/

# Crawl-delay for others
Crawl-delay: 10

# Sitemap
Sitemap: https://ashu.devinit.in/sitemap.xml